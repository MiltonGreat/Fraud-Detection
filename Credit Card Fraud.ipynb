{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7606dcbd-5da2-42dc-aa5e-9f5d5394590d",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "\n",
    "- Handling class imbalance through SMOTE significantly improved the model's ability to detect fraudulent transactions.\n",
    "- High recall ensures minimal false negatives, reducing the likelihood of undetected fraud.\n",
    "- Random Forest's feature importance analysis provides valuable insights into the attributes most indicative of fraudulent behavior.\n",
    "\n",
    "### Key Results from Your Model\n",
    "\n",
    "By distinguishing fraudulent from legitimate transactions, the business can focus manual investigation efforts only on flagged (high-risk) transactions, reducing the workload on fraud investigation teams.\n",
    "\n",
    "- ROC-AUC Score: Indicates how well the model distinguishes fraud from legitimate transactions. \n",
    "- AUPRC: Measures precision-recall performance, critical for imbalanced datasets. Higher values ensure fewer false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8a98a-f5dd-4ae9-96e4-cf2e38931b18",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "1. Overfitting\n",
    "\n",
    "- Perfect Metrics: ROC-AUC, AUPRC, and classification report metrics all showing a score of 1.000 might indicate overfitting, especially if the test data is not representative of real-world scenarios.\n",
    "- Cause:\n",
    "    - SMOTE creates synthetic samples, which might introduce data artifacts that are too easy for the model to classify.\n",
    "    - The training and test sets might not include enough real-world variability.\n",
    "    - Impact: The model may perform poorly on unseen data where fraudulent patterns differ.\n",
    "\n",
    "2. Dependency on SMOTE\n",
    "\n",
    "- Issue: SMOTE balances the dataset artificially by generating synthetic samples. While this improves training, it does not reflect the real-world imbalance of fraudulent vs. non-fraudulent transactions.\n",
    "- Impact: The model might face challenges when deployed in production, where the imbalance is extreme (e.g., fraud cases < 0.1%).\n",
    "- Solution: Explore ensemble techniques or anomaly detection models that handle imbalanced datasets without relying heavily on resampling.\n",
    "\n",
    "3. Lack of Feature Importance Analysis\n",
    "\n",
    "- Issue: The project does not explicitly analyze which features are most important for detecting fraud.\n",
    "- Impact: Without understanding feature importance, it is difficult to improve data collection or identify potential biases in the data.\n",
    "- Solution: Use the Random Forest feature importance scores or SHAP values to gain insights into the factors driving predictions.\n",
    "\n",
    "4. Model Interpretability\n",
    "\n",
    "- Issue: Random Forests are not inherently interpretable, making it hard to explain predictions to stakeholders or regulators.\n",
    "- Impact: Businesses may face difficulties in justifying flagged transactions to customers or complying with regulatory requirements.\n",
    "- Solution: Complement the model with interpretable methods, such as logistic regression or rule-based systems, for explainability in critical cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f91fe35-fd7d-4bd2-978f-fad752370ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE  # SMOTE for oversampling the minority class\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669dd20e-f6ab-4f1f-b74a-bdff60183c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted: ['creditcard.csv']\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Path to the zip file\n",
    "zip_file = 'Credit Card Fraud1.zip'\n",
    "extract_folder = 'Credit Card Fraud1'  \n",
    "\n",
    "# Extract the contents of the zip file\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "# Check if the file exists after extraction\n",
    "extracted_files = os.listdir(extract_folder)\n",
    "print(f\"Files extracted: {extracted_files}\")\n",
    "\n",
    "# Now load the CSV file\n",
    "data = pd.read_csv(os.path.join(extract_folder, 'creditcard.csv'))\n",
    "\n",
    "# Inspect the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values and general information\n",
    "print(data.info())\n",
    "\n",
    "# Check for class distribution\n",
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c39fbc-e3ab-4e6e-8c9d-1d31439d2674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before splitting:\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Feature columns (X) and target column (y)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Standardize all features (including 'Time' and 'Amount')\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Scale all features\n",
    "\n",
    "# Convert the scaled data back to DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Check the distribution of the classes before splitting\n",
    "print(\"Class distribution before splitting:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35389ebe-176b-4581-9904-c62a67136106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after SMOTE oversampling:\n",
      "Class\n",
      "0    284315\n",
      "1    284315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance by oversampling the minority class (frauds)\n",
    "# Using SMOTE for oversampling the fraud cases (Class == 1)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"\\nClass distribution after SMOTE oversampling:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4dce09a-8052-42fa-98c3-d1b701f9d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best Parameters: {'class_weight': None, 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': ['balanced', None]  # Adding class weight to handle imbalance better\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV with StratifiedKFold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=StratifiedKFold(n_splits=3), n_jobs=-1, verbose=2, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from GridSearchCV\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb44c838-d489-472d-b0a9-504c307f9951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "ROC-AUC Score: 1.0000\n",
      "Area Under the Precision-Recall Curve (AUPRC): 1.0000\n",
      "Model saved as 'credit_card_fraud_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set using the best parameters\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "y_pred_proba = best_rf_model.predict_proba(X_test)[:, 1]  # Get probability scores for ROC-AUC\n",
    "\n",
    "# Evaluate the model's performance using the AUPRC metric\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "auprc = auc(recall, precision)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate the ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Print the AUPRC score\n",
    "print(f\"Area Under the Precision-Recall Curve (AUPRC): {auprc:.4f}\")\n",
    "\n",
    "# Save the Model (Optional)\n",
    "joblib.dump(best_rf_model, 'credit_card_fraud_model.pkl')\n",
    "print(\"Model saved as 'credit_card_fraud_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
